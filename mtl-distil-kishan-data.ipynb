{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b11dbc7",
   "metadata": {
    "papermill": {
     "duration": 0.009361,
     "end_time": "2024-04-19T09:44:06.624916",
     "exception": false,
     "start_time": "2024-04-19T09:44:06.615555",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Teacher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21d71f40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-19T09:44:06.644041Z",
     "iopub.status.busy": "2024-04-19T09:44:06.643707Z",
     "iopub.status.idle": "2024-04-19T09:44:17.020044Z",
     "shell.execute_reply": "2024-04-19T09:44:17.019037Z"
    },
    "papermill": {
     "duration": 10.38861,
     "end_time": "2024-04-19T09:44:17.022426",
     "exception": false,
     "start_time": "2024-04-19T09:44:06.633816",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fd7b9847b10>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from skimage import io\n",
    "from skimage.transform import resize\n",
    "import scipy.io as spio\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import sys\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score, r2_score, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data.dataset import Subset\n",
    "torch.manual_seed(1234) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fb0024b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-19T09:44:17.042523Z",
     "iopub.status.busy": "2024-04-19T09:44:17.042019Z",
     "iopub.status.idle": "2024-04-19T09:44:17.049384Z",
     "shell.execute_reply": "2024-04-19T09:44:17.048575Z"
    },
    "papermill": {
     "duration": 0.019488,
     "end_time": "2024-04-19T09:44:17.051430",
     "exception": false,
     "start_time": "2024-04-19T09:44:17.031942",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs = np.arange(1, 51)\n",
    "glass_accuracy_test = []\n",
    "gender_accuracy_test = []\n",
    "testing_error_pose = []\n",
    "glass_accuracy_train = []\n",
    "gender_accuracy_train = []\n",
    "training_error_pose = []\n",
    "val_error_pose = []\n",
    "glass_accuracy_val = []\n",
    "gender_accuracy_val = []\n",
    "best_val_loss = float('inf')\n",
    "best_model_state = None\n",
    "early_stopping_rounds = 5\n",
    "patience = 0\n",
    "NumEpochs = 50\n",
    "torch.manual_seed(1234) \n",
    "\n",
    "num_classes_task1 = 2 \n",
    "num_classes_task2 = 2 \n",
    "num_classes_task3 = 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7897793f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-19T09:44:17.070051Z",
     "iopub.status.busy": "2024-04-19T09:44:17.069780Z",
     "iopub.status.idle": "2024-04-19T09:44:17.155574Z",
     "shell.execute_reply": "2024-04-19T09:44:17.154436Z"
    },
    "papermill": {
     "duration": 0.097337,
     "end_time": "2024-04-19T09:44:17.157704",
     "exception": false,
     "start_time": "2024-04-19T09:44:17.060367",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5427850b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-19T09:44:17.177677Z",
     "iopub.status.busy": "2024-04-19T09:44:17.177345Z",
     "iopub.status.idle": "2024-04-19T09:44:17.182003Z",
     "shell.execute_reply": "2024-04-19T09:44:17.181092Z"
    },
    "papermill": {
     "duration": 0.016915,
     "end_time": "2024-04-19T09:44:17.184040",
     "exception": false,
     "start_time": "2024-04-19T09:44:17.167125",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_size = [224, 224]\n",
    "startFrom=0\n",
    "# NumEpochs = 30\n",
    "batch_size = 100\n",
    "threadsTraining=1  \n",
    "dataset_path='/kaggle/input/mtl-aflw-data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d827ff0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-19T09:44:17.204685Z",
     "iopub.status.busy": "2024-04-19T09:44:17.203915Z",
     "iopub.status.idle": "2024-04-19T09:44:17.586361Z",
     "shell.execute_reply": "2024-04-19T09:44:17.585179Z"
    },
    "papermill": {
     "duration": 0.395129,
     "end_time": "2024-04-19T09:44:17.589210",
     "exception": false,
     "start_time": "2024-04-19T09:44:17.194081",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "imagesPath='/kaggle/input/mtl-aflw-data/cropped_resized_AFLW/images'\n",
    "mat=spio.loadmat('/kaggle/input/mtl-aflw-data/cropped_resized_AFLW/matrices/dataAFLW.mat')\n",
    "mat2=spio.loadmat('/kaggle/input/mtl-aflw-data/cropped_resized_AFLW/matrices/protocolAFLW.mat')\n",
    "\n",
    "PresenceGender=mat2['TrainMask_Gender']\n",
    "PresenceGlasses=mat2['TrainMask_Glasses']\n",
    "PresencePose=mat2['TrainMask_Pose']\n",
    "LabelPresenceMat=np.concatenate((PresenceGender, PresenceGlasses, PresencePose))\n",
    "LabelPresenceMat=np.transpose(LabelPresenceMat)\n",
    "TrainingSampleCount_taskWise=np.sum(LabelPresenceMat,axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc71c46e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-19T09:44:17.610007Z",
     "iopub.status.busy": "2024-04-19T09:44:17.608955Z",
     "iopub.status.idle": "2024-04-19T09:44:17.613689Z",
     "shell.execute_reply": "2024-04-19T09:44:17.612906Z"
    },
    "papermill": {
     "duration": 0.016821,
     "end_time": "2024-04-19T09:44:17.615707",
     "exception": false,
     "start_time": "2024-04-19T09:44:17.598886",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "elementsInTest = int(PresenceGender.shape[1]*0.3)\n",
    "TrainingSampleCount = int(PresenceGender.shape[1]*0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e971664",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-19T09:44:17.634295Z",
     "iopub.status.busy": "2024-04-19T09:44:17.634021Z",
     "iopub.status.idle": "2024-04-19T09:44:17.644102Z",
     "shell.execute_reply": "2024-04-19T09:44:17.643212Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.021509,
     "end_time": "2024-04-19T09:44:17.645944",
     "exception": false,
     "start_time": "2024-04-19T09:44:17.624435",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def loadCompleteDataset(startFrom, dataset_path,TrainingSampleCount):\n",
    "    ArrayFaceID=mat['ArrayFaceID']\n",
    "    ArrayGender_oneHot=mat['ArrayGender_oneHot']\n",
    "    ArrayGlasses_oneHot=mat['ArrayGlasses_oneHot']\n",
    "    ArraysPose=mat['ArraysPose']\n",
    "    \n",
    "    delMask=np.arange(startFrom,startFrom+elementsInTest)\n",
    "    \n",
    "    TestArrayFaceID = ArrayFaceID[startFrom:startFrom+elementsInTest:1,:]\n",
    "    TrainArrayFaceID = ArrayFaceID\n",
    "    TrainArrayFaceID = np.delete(TrainArrayFaceID,delMask,axis=0)\n",
    "    TestStrNames = [str(i) for i in TestArrayFaceID]\n",
    "    TestStrNames = [i[1:6] for i in TestStrNames]\n",
    "    TrainStrNames = [str(i) for i in TrainArrayFaceID]\n",
    "    TrainStrNames = [i[1:6] for i in TrainStrNames]\n",
    "    \n",
    "    TestArrayGender_oneHot = ArrayGender_oneHot[startFrom:startFrom+elementsInTest:1,:]\n",
    "    TrainArrayGender_oneHot = ArrayGender_oneHot\n",
    "    TrainArrayGender_oneHot = np.delete(TrainArrayGender_oneHot,delMask,axis=0)\n",
    "    \n",
    "    TestArrayGlasses_oneHot = ArrayGlasses_oneHot[startFrom:startFrom+elementsInTest:1,:]\n",
    "    TrainArrayGlasses_oneHot = ArrayGlasses_oneHot\n",
    "    TrainArrayGlasses_oneHot = np.delete(TrainArrayGlasses_oneHot,delMask,axis=0)\n",
    "    \n",
    "    TestArraysPose = ArraysPose[startFrom:startFrom+elementsInTest:1,:]\n",
    "    TrainArraysPose = ArraysPose\n",
    "    TrainArraysPose = np.delete(TrainArraysPose,delMask,axis=0)\n",
    "\n",
    "    dataset_AFLW = datasetClass_AFLW(TrainStrNames, TrainArrayGender_oneHot, TrainArrayGlasses_oneHot, TrainArraysPose, LabelPresenceMat, imagesPath, TrainingSampleCount)\n",
    "    dataset_AFLW_Test = datasetClass_AFLW_test(TestStrNames, TestArrayGender_oneHot, TestArrayGlasses_oneHot, TestArraysPose, imagesPath)\n",
    "    return dataset_AFLW, TrainingSampleCount_taskWise.astype(float), dataset_AFLW_Test, elementsInTest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9fc4e97c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-19T09:44:17.666323Z",
     "iopub.status.busy": "2024-04-19T09:44:17.666030Z",
     "iopub.status.idle": "2024-04-19T09:44:17.675181Z",
     "shell.execute_reply": "2024-04-19T09:44:17.674372Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.020876,
     "end_time": "2024-04-19T09:44:17.677043",
     "exception": false,
     "start_time": "2024-04-19T09:44:17.656167",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class datasetClass_AFLW(Dataset):\n",
    "    def __init__(self, ArrayFaceID, ArrayGender_oneHot, ArrayGlasses_oneHot, ArraysPose, LabelPresenceMat, imagesPath, TrainingSampleCount):\n",
    "        self.ArrayFaceID=ArrayFaceID\n",
    "        self.ArrayGender_oneHot=torch.from_numpy(ArrayGender_oneHot)\n",
    "        self.ArrayGlasses_oneHot=torch.from_numpy(ArrayGlasses_oneHot)\n",
    "        self.ArraysPose=torch.from_numpy(ArraysPose)\n",
    "        self.imagePath=imagesPath\n",
    "        self.CountSamples = TrainingSampleCount#len(self.ArrayFaceID)\n",
    "        self.LabelPresenceMat=LabelPresenceMat\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        imageName=self.ArrayFaceID[index]\n",
    "        ## Original Clean Image [output]\n",
    "        im_path = os.path.join(self.imagePath,imageName+'.png')\n",
    "        img = io.imread(im_path)\n",
    "        #following line normalizes image to [0, 1]\n",
    "        img = resize(img, (img_size[0], img_size[1]))\n",
    "        img = img.transpose(2, 0, 1)\n",
    "        \n",
    "        TaskwiseLabelPresence=self.LabelPresenceMat[index]\n",
    "        \n",
    "        label_gender = self.ArrayGender_oneHot[index]\n",
    "        label_glass = self.ArrayGlasses_oneHot[index]\n",
    "        label_pose = self.ArraysPose[index]\n",
    "        return  img, label_gender, label_glass, label_pose, imageName, TaskwiseLabelPresence\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.CountSamples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "928e5b27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-19T09:44:17.695643Z",
     "iopub.status.busy": "2024-04-19T09:44:17.695354Z",
     "iopub.status.idle": "2024-04-19T09:44:17.702958Z",
     "shell.execute_reply": "2024-04-19T09:44:17.702147Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.019215,
     "end_time": "2024-04-19T09:44:17.704904",
     "exception": false,
     "start_time": "2024-04-19T09:44:17.685689",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class datasetClass_AFLW_test(Dataset):\n",
    "    def __init__(self, ArrayFaceID, ArrayGender_oneHot, ArrayGlasses_oneHot, ArraysPose, imagesPath):\n",
    "        self.ArrayFaceID=ArrayFaceID\n",
    "        self.ArrayGender_oneHot=torch.from_numpy(ArrayGender_oneHot)\n",
    "        self.ArrayGlasses_oneHot=torch.from_numpy(ArrayGlasses_oneHot)\n",
    "        self.ArraysPose=torch.from_numpy(ArraysPose)\n",
    "        self.imagePath=imagesPath\n",
    "        self.CountSamples = elementsInTest\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        imageName=self.ArrayFaceID[index]\n",
    "        ## Original Clean Image [output]\n",
    "        im_path = os.path.join(self.imagePath,imageName+'.png')\n",
    "        img = io.imread(im_path)\n",
    "        #following line normalizes image to [0, 1]\n",
    "        img = resize(img, (img_size[0], img_size[1]))\n",
    "        img = img.transpose(2, 0, 1)\n",
    "        \n",
    "        label_gender = self.ArrayGender_oneHot[index]\n",
    "        label_glass = self.ArrayGlasses_oneHot[index]\n",
    "        label_pose = self.ArraysPose[index]\n",
    "        return img, label_gender, label_glass, label_pose, imageName\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.CountSamples\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5383f01b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-19T09:44:17.723304Z",
     "iopub.status.busy": "2024-04-19T09:44:17.723047Z",
     "iopub.status.idle": "2024-04-19T09:44:18.763943Z",
     "shell.execute_reply": "2024-04-19T09:44:18.763056Z"
    },
    "papermill": {
     "duration": 1.052846,
     "end_time": "2024-04-19T09:44:18.766415",
     "exception": false,
     "start_time": "2024-04-19T09:44:17.713569",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(1234) \n",
    "dataset_AFLW, TrainingSampleCount_taskWise, dataset_AFLW_Test, elementsInTest = loadCompleteDataset(startFrom, dataset_path, TrainingSampleCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c131365",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-19T09:44:18.786347Z",
     "iopub.status.busy": "2024-04-19T09:44:18.786056Z",
     "iopub.status.idle": "2024-04-19T09:44:18.795727Z",
     "shell.execute_reply": "2024-04-19T09:44:18.795020Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.021879,
     "end_time": "2024-04-19T09:44:18.797865",
     "exception": false,
     "start_time": "2024-04-19T09:44:18.775986",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(1234) \n",
    "train_indices, val_indices = train_test_split(np.arange(len(dataset_AFLW)), test_size=0.3, random_state=42)\n",
    "train_dataloader = DataLoader(Subset(dataset_AFLW, train_indices), batch_size=batch_size, shuffle=True, num_workers=threadsTraining, drop_last=True)\n",
    "val_dataloader = DataLoader(Subset(dataset_AFLW, val_indices), batch_size=batch_size, shuffle=False, num_workers=threadsTraining, drop_last=True)\n",
    "test_dataloader = DataLoader(dataset_AFLW_Test, shuffle=False, num_workers=threadsTraining, batch_size=batch_size,drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77f64961",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-19T09:44:18.817639Z",
     "iopub.status.busy": "2024-04-19T09:44:18.817286Z",
     "iopub.status.idle": "2024-04-19T09:44:18.833946Z",
     "shell.execute_reply": "2024-04-19T09:44:18.833159Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.029309,
     "end_time": "2024-04-19T09:44:18.836159",
     "exception": false,
     "start_time": "2024-04-19T09:44:18.806850",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SharedNetwork(nn.Module): \n",
    "    def __init__(self):\n",
    "        super(SharedNetwork, self).__init__()\n",
    "        resnet = models.resnet18(pretrained=True)\n",
    "        self.shared_network = nn.Sequential(*list(resnet.children())[:-2])\n",
    "        self.gap = nn.Sequential(nn.AdaptiveAvgPool2d(1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        shared_embedding = self.gap(self.shared_network(x))\n",
    "        return shared_embedding\n",
    "\n",
    "class MultiTaskNetwork(nn.Module):\n",
    "    def __init__(self, num_classes_task1, num_classes_task2, num_classes_task3):\n",
    "        super(MultiTaskNetwork, self).__init__()\n",
    "        self.shared_net = SharedNetwork().to(device)\n",
    "        self.task1_head = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, num_classes_task1),\n",
    "            nn.Softmax()\n",
    "        ).to(device)\n",
    "            \n",
    "        self.task2_head = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, num_classes_task2),\n",
    "            nn.Softmax()\n",
    "        ).to(device)\n",
    "\n",
    "        self.task3_head = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, num_classes_task3),\n",
    "            nn.ReLU(inplace=True)\n",
    "        ).to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        shared_embedding = self.shared_net(x)\n",
    "        task1_output = self.task1_head(shared_embedding.view(shared_embedding.size(0), -1))\n",
    "        task2_output = self.task2_head(shared_embedding.view(shared_embedding.size(0), -1))\n",
    "        task3_output = self.task3_head(shared_embedding.view(shared_embedding.size(0), -1))\n",
    "        return task1_output, task2_output, task3_output\n",
    "\n",
    "class myMSElossPose(torch.nn.Module):\n",
    "    def __init__(self, batch_size):\n",
    "        super(myMSElossPose, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def forward(self, predicted, target):\n",
    "        BatchSampleCount=predicted.shape[0]\n",
    "        error = torch.sub(predicted,target)\n",
    "        squaredError = torch.mul(error, error)\n",
    "        allSum = torch.sum(squaredError)\n",
    "        FinalLoss = torch.div(allSum, 3*BatchSampleCount)\n",
    "        return FinalLoss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2e54d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-19T09:22:25.976094Z",
     "iopub.status.busy": "2024-04-19T09:22:25.975381Z",
     "iopub.status.idle": "2024-04-19T09:22:25.983080Z",
     "shell.execute_reply": "2024-04-19T09:22:25.982133Z",
     "shell.execute_reply.started": "2024-04-19T09:22:25.976062Z"
    },
    "papermill": {
     "duration": 0.009459,
     "end_time": "2024-04-19T09:44:18.854814",
     "exception": false,
     "start_time": "2024-04-19T09:44:18.845355",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85017824",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-19T09:44:18.874754Z",
     "iopub.status.busy": "2024-04-19T09:44:18.874404Z",
     "iopub.status.idle": "2024-04-19T09:44:18.884527Z",
     "shell.execute_reply": "2024-04-19T09:44:18.883561Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.022864,
     "end_time": "2024-04-19T09:44:18.886734",
     "exception": false,
     "start_time": "2024-04-19T09:44:18.863870",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_classification_metrics(labels, predictions):\n",
    "    predictions_index = np.argmax(predictions, axis=1)\n",
    "    labels_index = np.argmax(labels, axis=1)\n",
    "    true_1 = []\n",
    "    pred_1 = []\n",
    "    for i in range(len(predictions)):\n",
    "        true_1.append(labels[i][0])\n",
    "        if(predictions[i][0] >=0.5):\n",
    "            pred_1.append(1)\n",
    "        else:\n",
    "            pred_1.append(0)\n",
    "\n",
    "    true_2 = []\n",
    "    pred_2 = []\n",
    "    for i in range(len(predictions)):\n",
    "        true_2.append(labels[i][1])\n",
    "        if(predictions[i][1] >=0.5):\n",
    "            pred_2.append(1)\n",
    "        else:\n",
    "            pred_2.append(0)\n",
    "\n",
    "    precision_1 = precision_score(true_1, pred_1)\n",
    "    recall_1 = recall_score(true_1, pred_1)\n",
    "    accuracy_1 = accuracy_score(true_1, pred_1)\n",
    "    f1_1 = f1_score(true_1, pred_1)\n",
    "\n",
    "    precision_2 = precision_score(true_2, pred_2)\n",
    "    recall_2 = recall_score(true_2, pred_2)\n",
    "    accuracy_2 = accuracy_score(true_2, pred_2)\n",
    "    f1_2 = f1_score(true_2, pred_2)\n",
    "\n",
    "\n",
    "    print('For Class 0:')\n",
    "    print(f\"Precision_0: {precision_1:.4f}, Recall_0: {recall_1:.4f}, Accuracy_0: {accuracy_1:.4f}, F1 Score_0: {f1_1:.4f}\")\n",
    "    print('For Class 1:')\n",
    "    print(f\"Precision_1: {precision_2:.4f}, Recall_1: {recall_2:.4f}, Accuracy_1: {accuracy_2:.4f}, F1 Score_1: {f1_2:.4f}\")\n",
    "    return accuracy_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e384812",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-19T09:44:18.906177Z",
     "iopub.status.busy": "2024-04-19T09:44:18.905629Z",
     "iopub.status.idle": "2024-04-19T09:44:19.963449Z",
     "shell.execute_reply": "2024-04-19T09:44:19.962592Z"
    },
    "papermill": {
     "duration": 1.069975,
     "end_time": "2024-04-19T09:44:19.965889",
     "exception": false,
     "start_time": "2024-04-19T09:44:18.895914",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
      "100%|██████████| 44.7M/44.7M [00:00<00:00, 120MB/s]\n"
     ]
    }
   ],
   "source": [
    "multi_task_net = MultiTaskNetwork(num_classes_task1, num_classes_task2, num_classes_task3).to(device)\n",
    "\n",
    "for m in multi_task_net.modules():\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_normal_(m.weight)\n",
    "\n",
    "\n",
    "criterion_task1 = nn.BCELoss().to(device)\n",
    "criterion_task2 = nn.BCELoss().to(device)\n",
    "criterion_task3 = myMSElossPose(batch_size).to(device)\n",
    "\n",
    "\n",
    "optimizer = optim.SGD(multi_task_net.parameters(), lr=0.001, momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7cce7d1d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-19T09:44:19.986967Z",
     "iopub.status.busy": "2024-04-19T09:44:19.986386Z",
     "iopub.status.idle": "2024-04-19T09:44:20.003765Z",
     "shell.execute_reply": "2024-04-19T09:44:20.002900Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.029634,
     "end_time": "2024-04-19T09:44:20.005756",
     "exception": false,
     "start_time": "2024-04-19T09:44:19.976122",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def training_result(epoch, multi_task_net, train_dataloader):\n",
    "    criterion_task3 = myMSElossPose(batch_size).to(device)\n",
    "    multi_task_net.eval()\n",
    "\n",
    "    y_true_glass = []\n",
    "    y_pred_glass = []\n",
    "    y_true_gender = []\n",
    "    y_pred_gender = []\n",
    "    y_true_pose = []\n",
    "    y_pred_pose = []\n",
    "    R_te_errorPose=0\n",
    "    te_countPose=0\n",
    "\n",
    "    # Iterate over the test dataset\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(train_dataloader, 0):\n",
    "            img, label_gender, label_glass, label_pose, imageName, TaskwiseLabelPresence = data\n",
    "            img = img.to(device)\n",
    "            label_gender = label_gender.to(device)\n",
    "            label_glass = label_glass.to(device)\n",
    "            label_pose = label_pose.to(device)\n",
    "            TaskwiseLabelPresence = TaskwiseLabelPresence.numpy()\n",
    "            img, label_gender, label_glass, label_pose = img.float(), label_gender.float(), label_glass.float(), label_pose.float()\n",
    "\n",
    "            # Make predictions\n",
    "            FC_output_gender, FC_output_glasses, FC_output_angle = multi_task_net(img)\n",
    "\n",
    "            gender_IndSelect = np.where(TaskwiseLabelPresence[:, 0] == 1)\n",
    "            glasses_IndSelect = np.where(TaskwiseLabelPresence[:, 1] == 1)\n",
    "            pose_IndSelect = np.where(TaskwiseLabelPresence[:, 2] == 1)\n",
    "\n",
    "            # Calculate task-wise metrics\n",
    "            if gender_IndSelect[0].shape[0] != 0:\n",
    "                y_true_gender.append(label_gender)\n",
    "                y_pred_gender.append(FC_output_gender)\n",
    "\n",
    "            if glasses_IndSelect[0].shape[0] != 0:\n",
    "                y_true_glass.append(label_glass)\n",
    "                y_pred_glass.append(FC_output_glasses)\n",
    "\n",
    "            if pose_IndSelect[0].shape[0] != 0:\n",
    "                y_true_pose.append(label_pose)\n",
    "                y_pred_pose.append(FC_output_angle)\n",
    "                loss3 = criterion_task3(FC_output_angle, label_pose)\n",
    "                R_te_errorPose += loss3.item()\n",
    "                te_countPose = te_countPose+1\n",
    "\n",
    "   \n",
    "    y_true_gender = np.concatenate([t.cpu().numpy() for t in y_true_gender], axis=0)\n",
    "    y_pred_gender = np.concatenate([t.cpu().numpy() for t in y_pred_gender], axis=0)\n",
    "    y_true_glass = np.concatenate([t.cpu().numpy() for t in y_true_glass], axis=0)\n",
    "    y_pred_glass = np.concatenate([t.cpu().numpy() for t in y_pred_glass], axis=0)\n",
    "    y_true_pose = np.concatenate([t.cpu().numpy() for t in y_true_pose], axis=0)\n",
    "    y_pred_pose = np.concatenate([t.cpu().numpy() for t in y_pred_pose], axis=0)\n",
    "    y_true_pose = y_true_pose.reshape(-1)\n",
    "    y_pred_pose = y_pred_pose.reshape(-1)\n",
    "\n",
    "    # Print the results\n",
    "    r2 = r2_score(y_true_pose,y_pred_pose)\n",
    "    training_error_pose.append(R_te_errorPose/te_countPose)\n",
    "\n",
    "    print('No of epochs Trained: ',epoch+1)\n",
    "    print('For Gender Task:')\n",
    "    gender_accuracy_train.append(calculate_classification_metrics(y_true_gender,y_pred_gender))\n",
    "    print('For Glasses Task:')\n",
    "    glass_accuracy_train.append(calculate_classification_metrics(y_true_glass,y_pred_glass))\n",
    "    print('For Pose Task:')       \n",
    "    print(f\"R2 Score: {r2:.4f}\")\n",
    "    print('Training error pose: ' + str(R_te_errorPose/te_countPose))\n",
    "    multi_task_net.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e1ad113",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-19T09:44:20.025600Z",
     "iopub.status.busy": "2024-04-19T09:44:20.025298Z",
     "iopub.status.idle": "2024-04-19T09:44:20.043308Z",
     "shell.execute_reply": "2024-04-19T09:44:20.042426Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.030278,
     "end_time": "2024-04-19T09:44:20.045355",
     "exception": false,
     "start_time": "2024-04-19T09:44:20.015077",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def validation_result(epoch, multi_task_net, val_dataloader):\n",
    "    criterion_task3 = myMSElossPose(batch_size).to(device)\n",
    "    multi_task_net.eval()\n",
    "\n",
    "    y_true_gender, y_pred_gender = [], []\n",
    "    y_true_glass, y_pred_glass = [], []\n",
    "    y_true_pose, y_pred_pose = [], []\n",
    "    R_te_errorPose=0\n",
    "    te_countPose=0\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(val_dataloader, 0):\n",
    "            img, label_gender, label_glass, label_pose, imageName, TaskwiseLabelPresence = data\n",
    "            img = img.to(device)\n",
    "            label_gender = label_gender.to(device)\n",
    "            label_glass = label_glass.to(device)\n",
    "            label_pose = label_pose.to(device)\n",
    "            TaskwiseLabelPresence = TaskwiseLabelPresence.numpy()\n",
    "            img, label_gender, label_glass, label_pose = img.float(), label_gender.float(), label_glass.float(), label_pose.float()\n",
    "\n",
    "            FC_output_gender, FC_output_glasses, FC_output_angle = multi_task_net(img)\n",
    "\n",
    "            gender_IndSelect = np.where(TaskwiseLabelPresence[:, 0] == 1)\n",
    "            glasses_IndSelect = np.where(TaskwiseLabelPresence[:, 1] == 1)\n",
    "            pose_IndSelect = np.where(TaskwiseLabelPresence[:, 2] == 1)\n",
    "\n",
    "            if gender_IndSelect[0].shape[0] != 0:\n",
    "                y_true_gender.append(label_gender)\n",
    "                y_pred_gender.append(FC_output_gender)\n",
    "\n",
    "            if glasses_IndSelect[0].shape[0] != 0:\n",
    "                y_true_glass.append(label_glass)\n",
    "                y_pred_glass.append(FC_output_glasses)\n",
    "\n",
    "            if pose_IndSelect[0].shape[0] != 0:\n",
    "                y_true_pose.append(label_pose)\n",
    "                y_pred_pose.append(FC_output_angle)\n",
    "                loss3 = criterion_task3(FC_output_angle, label_pose)\n",
    "                R_te_errorPose += loss3.item()\n",
    "                te_countPose = te_countPose+1\n",
    "\n",
    "\n",
    "    y_true_gender = np.concatenate([t.cpu().numpy() for t in y_true_gender], axis=0)\n",
    "    y_pred_gender = np.concatenate([t.cpu().numpy() for t in y_pred_gender], axis=0)\n",
    "    y_true_glass = np.concatenate([t.cpu().numpy() for t in y_true_glass], axis=0)\n",
    "    y_pred_glass = np.concatenate([t.cpu().numpy() for t in y_pred_glass], axis=0)\n",
    "    y_true_pose = np.concatenate([t.cpu().numpy() for t in y_true_pose], axis=0)\n",
    "    y_pred_pose = np.concatenate([t.cpu().numpy() for t in y_pred_pose], axis=0)\n",
    "    y_true_pose = y_true_pose.reshape(-1)\n",
    "    y_pred_pose = y_pred_pose.reshape(-1)\n",
    "\n",
    "    # Print the results\n",
    "    r2 = r2_score(y_true_pose,y_pred_pose)\n",
    "    val_error_pose.append(R_te_errorPose/te_countPose)\n",
    "\n",
    "    print('No of epochs Trained: ',epoch+1)\n",
    "    print('For Gender Task:')\n",
    "    gender_accuracy_val.append(calculate_classification_metrics(y_true_gender,y_pred_gender))\n",
    "    print('For Glasses Task:')\n",
    "    glass_accuracy_val.append(calculate_classification_metrics(y_true_glass,y_pred_glass))\n",
    "    print('For Pose Task:')       \n",
    "    print(f\"R2 Score: {r2:.4f}\")\n",
    "    print('Training error pose: ' + str(R_te_errorPose/te_countPose))\n",
    "    multi_task_net.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "120168cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-19T09:44:20.066300Z",
     "iopub.status.busy": "2024-04-19T09:44:20.065993Z",
     "iopub.status.idle": "2024-04-19T09:44:20.080495Z",
     "shell.execute_reply": "2024-04-19T09:44:20.079660Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.027413,
     "end_time": "2024-04-19T09:44:20.082581",
     "exception": false,
     "start_time": "2024-04-19T09:44:20.055168",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def testing_result(epoch, multi_task_net, test_dataloader):\n",
    "    \n",
    "        criterion_task3 = myMSElossPose(batch_size).to(device)\n",
    "        multi_task_net.eval()\n",
    "\n",
    "        y_true_glass = []\n",
    "        y_pred_glass = []\n",
    "        y_true_gender = []\n",
    "        y_pred_gender = []\n",
    "        y_true_pose = []\n",
    "        y_pred_pose = []\n",
    "        R_te_errorPose=0\n",
    "        te_countPose=0\n",
    "\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(test_dataloader, 0):\n",
    "                img, label_gender, label_glass, label_pose, imageName = data\n",
    "                img = img.to(device)\n",
    "                label_gender = label_gender.to(device)\n",
    "                label_glass = label_glass.to(device)\n",
    "                label_pose = label_pose.to(device)\n",
    "                img, label_gender, label_glass, label_pose = img.float(), label_gender.float(), label_glass.float(), label_pose.float()\n",
    "\n",
    "                # Make predictions\n",
    "                FC_output_gender, FC_output_glasses, FC_output_angle = multi_task_net(img)\n",
    "\n",
    "\n",
    "                # Calculate task-wise metrics\n",
    "                y_true_gender.append(label_gender)\n",
    "                y_pred_gender.append(FC_output_gender)\n",
    "\n",
    "                y_true_glass.append(label_glass)\n",
    "                y_pred_glass.append(FC_output_glasses)\n",
    "\n",
    "                y_true_pose.append(label_pose)\n",
    "                y_pred_pose.append(FC_output_angle)\n",
    "                loss3 = criterion_task3(FC_output_angle, label_pose)\n",
    "                R_te_errorPose += loss3.item()\n",
    "                te_countPose = te_countPose+1\n",
    "\n",
    "        \n",
    "        y_true_gender = np.concatenate([t.cpu().numpy() for t in y_true_gender], axis=0)\n",
    "        y_pred_gender = np.concatenate([t.cpu().numpy() for t in y_pred_gender], axis=0)\n",
    "        y_true_glass = np.concatenate([t.cpu().numpy() for t in y_true_glass], axis=0)\n",
    "        y_pred_glass = np.concatenate([t.cpu().numpy() for t in y_pred_glass], axis=0)\n",
    "        y_true_pose = np.concatenate([t.cpu().numpy() for t in y_true_pose], axis=0)\n",
    "        y_pred_pose = np.concatenate([t.cpu().numpy() for t in y_pred_pose], axis=0)\n",
    "        y_true_pose = y_true_pose.reshape(-1)\n",
    "        y_pred_pose = y_pred_pose.reshape(-1)\n",
    "\n",
    "        r2 = r2_score(y_true_pose,y_pred_pose)\n",
    "        testing_error_pose.append(R_te_errorPose/te_countPose)\n",
    "\n",
    "        # Print the results\n",
    "        print('No of epochs Trained: ',epoch+1)\n",
    "        print('For Gender Task:')\n",
    "        gender_accuracy_test.append(calculate_classification_metrics(y_true_gender,y_pred_gender))\n",
    "        print('For Glasses Task:')\n",
    "        glass_accuracy_test.append(calculate_classification_metrics(y_true_glass,y_pred_glass))\n",
    "        print('For Pose Task:')       \n",
    "        print(f\"R2 Score: {r2:.4f}\")\n",
    "        print('Testing error pose: ' + str(R_te_errorPose/te_countPose))\n",
    "        multi_task_net.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "61a0a6a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-19T09:44:20.102376Z",
     "iopub.status.busy": "2024-04-19T09:44:20.102141Z",
     "iopub.status.idle": "2024-04-19T11:57:49.767055Z",
     "shell.execute_reply": "2024-04-19T11:57:49.765510Z"
    },
    "papermill": {
     "duration": 8009.700894,
     "end_time": "2024-04-19T11:57:49.792919",
     "exception": false,
     "start_time": "2024-04-19T09:44:20.092025",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task1 Loss: 0.7286, Task2 Loss: 0.3507, Task3 Loss: 0.1670, Total Loss: 1.2463\n",
      "Training Result\n",
      "No of epochs Trained:  1\n",
      "For Gender Task:\n",
      "For Class 0:\n",
      "Precision_0: 0.5750, Recall_0: 0.9542, Accuracy_0: 0.5689, F1 Score_0: 0.7176\n",
      "For Class 1:\n",
      "Precision_1: 0.4481, Recall_1: 0.0500, Accuracy_1: 0.5689, F1 Score_1: 0.0900\n",
      "For Glasses Task:\n",
      "For Class 0:\n",
      "Precision_0: 0.9288, Recall_0: 1.0000, Accuracy_0: 0.9288, F1 Score_0: 0.9631\n",
      "For Class 1:\n",
      "Precision_1: 0.0000, Recall_1: 0.0000, Accuracy_1: 0.9288, F1 Score_1: 0.0000\n",
      "For Pose Task:\n",
      "R2 Score: -18.1603\n",
      "Training error pose: 0.13548252022410012\n",
      "Validation Result\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of epochs Trained:  1\n",
      "For Gender Task:\n",
      "For Class 0:\n",
      "Precision_0: 0.5843, Recall_0: 0.9479, Accuracy_0: 0.5774, F1 Score_0: 0.7230\n",
      "For Class 1:\n",
      "Precision_1: 0.4619, Recall_1: 0.0622, Accuracy_1: 0.5774, F1 Score_1: 0.1096\n",
      "For Glasses Task:\n",
      "For Class 0:\n",
      "Precision_0: 0.9229, Recall_0: 1.0000, Accuracy_0: 0.9229, F1 Score_0: 0.9599\n",
      "For Class 1:\n",
      "Precision_1: 0.0000, Recall_1: 0.0000, Accuracy_1: 0.9229, F1 Score_1: 0.0000\n",
      "For Pose Task:\n",
      "R2 Score: -17.7745\n",
      "Training error pose: 0.1328635750072343\n",
      "Testing Result\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of epochs Trained:  1\n",
      "For Gender Task:\n",
      "For Class 0:\n",
      "Precision_0: 0.6190, Recall_0: 0.9619, Accuracy_0: 0.6104, F1 Score_0: 0.7533\n",
      "For Class 1:\n",
      "Precision_1: 0.4000, Recall_1: 0.0411, Accuracy_1: 0.6104, F1 Score_1: 0.0745\n",
      "For Glasses Task:\n",
      "For Class 0:\n",
      "Precision_0: 0.9220, Recall_0: 1.0000, Accuracy_0: 0.9220, F1 Score_0: 0.9594\n",
      "For Class 1:\n",
      "Precision_1: 0.0000, Recall_1: 0.0000, Accuracy_1: 0.9220, F1 Score_1: 0.0000\n",
      "For Pose Task:\n",
      "R2 Score: -21.3387\n",
      "Testing error pose: 0.12922104170509413\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task1 Loss: 0.6988, Task2 Loss: 0.2616, Task3 Loss: 0.0504, Total Loss: 1.0108\n",
      "Training Result\n",
      "No of epochs Trained:  2\n",
      "For Gender Task:\n",
      "For Class 0:\n",
      "Precision_0: 0.5778, Recall_0: 0.9885, Accuracy_0: 0.5789, F1 Score_0: 0.7293\n",
      "For Class 1:\n",
      "Precision_1: 0.6405, Recall_1: 0.0277, Accuracy_1: 0.5789, F1 Score_1: 0.0531\n",
      "For Glasses Task:\n",
      "For Class 0:\n",
      "Precision_0: 0.9318, Recall_0: 0.9827, Accuracy_0: 0.9171, F1 Score_0: 0.9566\n",
      "For Class 1:\n",
      "Precision_1: 0.2083, Recall_1: 0.0593, Accuracy_1: 0.9171, F1 Score_1: 0.0923\n",
      "For Pose Task:\n",
      "R2 Score: -7.6355\n",
      "Training error pose: 0.061000415449400984\n",
      "Validation Result\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of epochs Trained:  2\n",
      "For Gender Task:\n",
      "For Class 0:\n",
      "Precision_0: 0.5820, Recall_0: 0.9848, Accuracy_0: 0.5797, F1 Score_0: 0.7316\n",
      "For Class 1:\n",
      "Precision_1: 0.4364, Recall_1: 0.0164, Accuracy_1: 0.5797, F1 Score_1: 0.0316\n",
      "For Glasses Task:\n",
      "For Class 0:\n",
      "Precision_0: 0.9249, Recall_0: 0.9799, Accuracy_0: 0.9080, F1 Score_0: 0.9516\n",
      "For Class 1:\n",
      "Precision_1: 0.1667, Recall_1: 0.0481, Accuracy_1: 0.9080, F1 Score_1: 0.0747\n",
      "For Pose Task:\n",
      "R2 Score: -8.0605\n",
      "Training error pose: 0.06411916453923498\n",
      "Testing Result\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of epochs Trained:  2\n",
      "For Gender Task:\n",
      "For Class 0:\n",
      "Precision_0: 0.6174, Recall_0: 0.9841, Accuracy_0: 0.6131, F1 Score_0: 0.7588\n",
      "For Class 1:\n",
      "Precision_1: 0.3243, Recall_1: 0.0123, Accuracy_1: 0.6131, F1 Score_1: 0.0238\n",
      "For Glasses Task:\n",
      "For Class 0:\n",
      "Precision_0: 0.9260, Recall_0: 0.9815, Accuracy_0: 0.9106, F1 Score_0: 0.9529\n",
      "For Class 1:\n",
      "Precision_1: 0.2500, Recall_1: 0.0729, Accuracy_1: 0.9106, F1 Score_1: 0.1128\n",
      "For Pose Task:\n",
      "R2 Score: -7.5314\n",
      "Testing error pose: 0.04935083709949372\n",
      "Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task1 Loss: 0.6941, Task2 Loss: 0.2539, Task3 Loss: 0.0309, Total Loss: 0.9790\n",
      "Training Result\n",
      "No of epochs Trained:  3\n",
      "For Gender Task:\n",
      "For Class 0:\n",
      "Precision_0: 0.5742, Recall_0: 0.9998, Accuracy_0: 0.5743, F1 Score_0: 0.7295\n",
      "For Class 1:\n",
      "Precision_1: 0.8000, Recall_1: 0.0011, Accuracy_1: 0.5743, F1 Score_1: 0.0023\n",
      "For Glasses Task:\n",
      "For Class 0:\n",
      "Precision_0: 0.9289, Recall_0: 1.0000, Accuracy_0: 0.9289, F1 Score_0: 0.9631\n",
      "For Class 1:\n",
      "Precision_1: 0.0000, Recall_1: 0.0000, Accuracy_1: 0.9289, F1 Score_1: 0.0000\n",
      "For Pose Task:\n",
      "R2 Score: -3.1829\n",
      "Training error pose: 0.029575151032263255\n",
      "Validation Result\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of epochs Trained:  3\n",
      "For Gender Task:\n",
      "For Class 0:\n",
      "Precision_0: 0.5820, Recall_0: 1.0000, Accuracy_0: 0.5823, F1 Score_0: 0.7358\n",
      "For Class 1:\n",
      "Precision_1: 1.0000, Recall_1: 0.0014, Accuracy_1: 0.5823, F1 Score_1: 0.0027\n",
      "For Glasses Task:\n",
      "For Class 0:\n",
      "Precision_0: 0.9229, Recall_0: 1.0000, Accuracy_0: 0.9229, F1 Score_0: 0.9599\n",
      "For Class 1:\n",
      "Precision_1: 0.0000, Recall_1: 0.0000, Accuracy_1: 0.9229, F1 Score_1: 0.0000\n",
      "For Pose Task:\n",
      "R2 Score: -3.2996\n",
      "Training error pose: 0.030427213971103942\n",
      "Testing Result\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of epochs Trained:  3\n",
      "For Gender Task:\n",
      "For Class 0:\n",
      "Precision_0: 0.6179, Recall_0: 0.9987, Accuracy_0: 0.6175, F1 Score_0: 0.7635\n",
      "For Class 1:\n",
      "Precision_1: 0.0000, Recall_1: 0.0000, Accuracy_1: 0.6175, F1 Score_1: 0.0000\n",
      "For Glasses Task:\n",
      "For Class 0:\n",
      "Precision_0: 0.9220, Recall_0: 1.0000, Accuracy_0: 0.9220, F1 Score_0: 0.9594\n",
      "For Class 1:\n",
      "Precision_1: 0.0000, Recall_1: 0.0000, Accuracy_1: 0.9220, F1 Score_1: 0.0000\n",
      "For Pose Task:\n",
      "R2 Score: -4.1938\n",
      "Testing error pose: 0.03004430280085288\n",
      "Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task1 Loss: 0.6742, Task2 Loss: 0.2513, Task3 Loss: 0.0203, Total Loss: 0.9457\n",
      "Training Result\n",
      "No of epochs Trained:  4\n",
      "For Gender Task:\n",
      "For Class 0:\n",
      "Precision_0: 0.5833, Recall_0: 0.9292, Accuracy_0: 0.5787, F1 Score_0: 0.7167\n",
      "For Class 1:\n",
      "Precision_1: 0.5300, Recall_1: 0.1073, Accuracy_1: 0.5787, F1 Score_1: 0.1785\n",
      "For Glasses Task:\n",
      "For Class 0:\n",
      "Precision_0: 0.9336, Recall_0: 0.9725, Accuracy_0: 0.9102, F1 Score_0: 0.9527\n",
      "For Class 1:\n",
      "Precision_1: 0.2119, Recall_1: 0.0966, Accuracy_1: 0.9102, F1 Score_1: 0.1327\n",
      "For Pose Task:\n",
      "R2 Score: -1.4737\n",
      "Training error pose: 0.017482635924166226\n",
      "Validation Result\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of epochs Trained:  4\n",
      "For Gender Task:\n",
      "For Class 0:\n",
      "Precision_0: 0.5893, Recall_0: 0.9155, Accuracy_0: 0.5797, F1 Score_0: 0.7171\n",
      "For Class 1:\n",
      "Precision_1: 0.4896, Recall_1: 0.1127, Accuracy_1: 0.5797, F1 Score_1: 0.1832\n",
      "For Glasses Task:\n",
      "For Class 0:\n",
      "Precision_0: 0.9259, Recall_0: 0.9709, Accuracy_0: 0.9014, F1 Score_0: 0.9479\n",
      "For Class 1:\n",
      "Precision_1: 0.1681, Recall_1: 0.0704, Accuracy_1: 0.9014, F1 Score_1: 0.0992\n",
      "For Pose Task:\n",
      "R2 Score: -1.6127\n",
      "Training error pose: 0.018489495159259864\n",
      "Testing Result\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of epochs Trained:  4\n",
      "For Gender Task:\n",
      "For Class 0:\n",
      "Precision_0: 0.6212, Recall_0: 0.8735, Accuracy_0: 0.5925, F1 Score_0: 0.7261\n",
      "For Class 1:\n",
      "Precision_1: 0.4018, Recall_1: 0.1376, Accuracy_1: 0.5925, F1 Score_1: 0.2050\n",
      "For Glasses Task:\n",
      "For Class 0:\n",
      "Precision_0: 0.9278, Recall_0: 0.9700, Accuracy_0: 0.9027, F1 Score_0: 0.9484\n",
      "For Class 1:\n",
      "Precision_1: 0.2337, Recall_1: 0.1080, Accuracy_1: 0.9027, F1 Score_1: 0.1478\n",
      "For Pose Task:\n",
      "R2 Score: -2.4323\n",
      "Testing error pose: 0.01985440945581478\n",
      "Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task1 Loss: 0.6681, Task2 Loss: 0.2486, Task3 Loss: 0.0136, Total Loss: 0.9303\n",
      "Training Result\n",
      "No of epochs Trained:  5\n",
      "For Gender Task:\n",
      "For Class 0:\n",
      "Precision_0: 0.5824, Recall_0: 0.9834, Accuracy_0: 0.5859, F1 Score_0: 0.7315\n",
      "For Class 1:\n",
      "Precision_1: 0.6950, Recall_1: 0.0509, Accuracy_1: 0.5859, F1 Score_1: 0.0948\n",
      "For Glasses Task:\n",
      "For Class 0:\n",
      "Precision_0: 0.9302, Recall_0: 0.9990, Accuracy_0: 0.9294, F1 Score_0: 0.9633\n",
      "For Class 1:\n",
      "Precision_1: 0.6522, Recall_1: 0.0253, Accuracy_1: 0.9294, F1 Score_1: 0.0487\n",
      "For Pose Task:\n",
      "R2 Score: -1.3434\n",
      "Training error pose: 0.016561604901609652\n",
      "Validation Result\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of epochs Trained:  5\n",
      "For Gender Task:\n",
      "For Class 0:\n",
      "Precision_0: 0.5901, Recall_0: 0.9794, Accuracy_0: 0.5923, F1 Score_0: 0.7365\n",
      "For Class 1:\n",
      "Precision_1: 0.6529, Recall_1: 0.0540, Accuracy_1: 0.5923, F1 Score_1: 0.0997\n",
      "For Glasses Task:\n",
      "For Class 0:\n",
      "Precision_0: 0.9236, Recall_0: 0.9988, Accuracy_0: 0.9226, F1 Score_0: 0.9597\n",
      "For Class 1:\n",
      "Precision_1: 0.4286, Recall_1: 0.0111, Accuracy_1: 0.9226, F1 Score_1: 0.0217\n",
      "For Pose Task:\n",
      "R2 Score: -1.4666\n",
      "Training error pose: 0.017455362901091575\n",
      "Testing Result\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of epochs Trained:  5\n",
      "For Gender Task:\n",
      "For Class 0:\n",
      "Precision_0: 0.6246, Recall_0: 0.9499, Accuracy_0: 0.6161, F1 Score_0: 0.7536\n",
      "For Class 1:\n",
      "Precision_1: 0.4820, Recall_1: 0.0755, Accuracy_1: 0.6161, F1 Score_1: 0.1306\n",
      "For Glasses Task:\n",
      "For Class 0:\n",
      "Precision_0: 0.9240, Recall_0: 0.9979, Accuracy_0: 0.9224, F1 Score_0: 0.9595\n",
      "For Class 1:\n",
      "Precision_1: 0.5455, Recall_1: 0.0302, Accuracy_1: 0.9224, F1 Score_1: 0.0571\n",
      "For Pose Task:\n",
      "R2 Score: -2.0305\n",
      "Testing error pose: 0.01753050936203377\n",
      "Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task1 Loss: 0.6582, Task2 Loss: 0.2379, Task3 Loss: 0.0127, Total Loss: 0.9088\n",
      "Training Result\n",
      "No of epochs Trained:  6\n",
      "For Gender Task:\n",
      "For Class 0:\n",
      "Precision_0: 0.6017, Recall_0: 0.8008, Accuracy_0: 0.5814, F1 Score_0: 0.6871\n",
      "For Class 1:\n",
      "Precision_1: 0.5161, Recall_1: 0.2861, Accuracy_1: 0.5814, F1 Score_1: 0.3681\n",
      "For Glasses Task:\n",
      "For Class 0:\n",
      "Precision_0: 0.9388, Recall_0: 0.9905, Accuracy_0: 0.9312, F1 Score_0: 0.9640\n",
      "For Class 1:\n",
      "Precision_1: 0.5576, Recall_1: 0.1559, Accuracy_1: 0.9312, F1 Score_1: 0.2437\n",
      "For Pose Task:\n",
      "R2 Score: -0.8802\n",
      "Training error pose: 0.013292618499821928\n",
      "Validation Result\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of epochs Trained:  6\n",
      "For Gender Task:\n",
      "For Class 0:\n",
      "Precision_0: 0.6132, Recall_0: 0.8006, Accuracy_0: 0.5903, F1 Score_0: 0.6945\n",
      "For Class 1:\n",
      "Precision_1: 0.5178, Recall_1: 0.2978, Accuracy_1: 0.5903, F1 Score_1: 0.3781\n",
      "For Glasses Task:\n",
      "For Class 0:\n",
      "Precision_0: 0.9292, Recall_0: 0.9870, Accuracy_0: 0.9186, F1 Score_0: 0.9572\n",
      "For Class 1:\n",
      "Precision_1: 0.3913, Recall_1: 0.1000, Accuracy_1: 0.9186, F1 Score_1: 0.1593\n",
      "For Pose Task:\n",
      "R2 Score: -0.9942\n",
      "Training error pose: 0.01411246910159077\n",
      "Testing Result\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of epochs Trained:  6\n",
      "For Gender Task:\n",
      "For Class 0:\n",
      "Precision_0: 0.6503, Recall_0: 0.7336, Accuracy_0: 0.5914, F1 Score_0: 0.6894\n",
      "For Class 1:\n",
      "Precision_1: 0.4556, Recall_1: 0.3611, Accuracy_1: 0.5914, F1 Score_1: 0.4029\n",
      "For Glasses Task:\n",
      "For Class 0:\n",
      "Precision_0: 0.9335, Recall_0: 0.9858, Accuracy_0: 0.9222, F1 Score_0: 0.9589\n",
      "For Class 1:\n",
      "Precision_1: 0.5037, Recall_1: 0.1709, Accuracy_1: 0.9222, F1 Score_1: 0.2552\n",
      "For Pose Task:\n",
      "R2 Score: -1.5710\n",
      "Testing error pose: 0.014872099072033284\n",
      "Epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task1 Loss: 0.6434, Task2 Loss: 0.2337, Task3 Loss: 0.0118, Total Loss: 0.8889\n",
      "Training Result\n",
      "No of epochs Trained:  7\n",
      "For Gender Task:\n",
      "For Class 0:\n",
      "Precision_0: 0.6759, Recall_0: 0.5919, Accuracy_0: 0.6031, F1 Score_0: 0.6311\n",
      "For Class 1:\n",
      "Precision_1: 0.5297, Recall_1: 0.6183, Accuracy_1: 0.6031, F1 Score_1: 0.5705\n",
      "For Glasses Task:\n",
      "For Class 0:\n",
      "Precision_0: 0.9430, Recall_0: 0.9826, Accuracy_0: 0.9287, F1 Score_0: 0.9624\n",
      "For Class 1:\n",
      "Precision_1: 0.4962, Recall_1: 0.2237, Accuracy_1: 0.9287, F1 Score_1: 0.3084\n",
      "For Pose Task:\n",
      "R2 Score: -1.0543\n",
      "Training error pose: 0.014514530245887947\n",
      "Validation Result\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of epochs Trained:  7\n",
      "For Gender Task:\n",
      "For Class 0:\n",
      "Precision_0: 0.6619, Recall_0: 0.5472, Accuracy_0: 0.5740, F1 Score_0: 0.5991\n",
      "For Class 1:\n",
      "Precision_1: 0.4926, Recall_1: 0.6113, Accuracy_1: 0.5740, F1 Score_1: 0.5456\n",
      "For Glasses Task:\n",
      "For Class 0:\n",
      "Precision_0: 0.9344, Recall_0: 0.9789, Accuracy_0: 0.9171, F1 Score_0: 0.9562\n",
      "For Class 1:\n",
      "Precision_1: 0.4138, Recall_1: 0.1778, Accuracy_1: 0.9171, F1 Score_1: 0.2487\n",
      "For Pose Task:\n",
      "R2 Score: -1.0525\n",
      "Training error pose: 0.014525118124272143\n",
      "Testing Result\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of epochs Trained:  7\n",
      "For Gender Task:\n",
      "For Class 0:\n",
      "Precision_0: 0.7084, Recall_0: 0.4437, Accuracy_0: 0.5431, F1 Score_0: 0.5456\n",
      "For Class 1:\n",
      "Precision_1: 0.4387, Recall_1: 0.7042, Accuracy_1: 0.5431, F1 Score_1: 0.5406\n",
      "For Glasses Task:\n",
      "For Class 0:\n",
      "Precision_0: 0.9386, Recall_0: 0.9747, Accuracy_0: 0.9178, F1 Score_0: 0.9563\n",
      "For Class 1:\n",
      "Precision_1: 0.4516, Recall_1: 0.2462, Accuracy_1: 0.9178, F1 Score_1: 0.3187\n",
      "For Pose Task:\n",
      "R2 Score: -1.6327\n",
      "Testing error pose: 0.015229306128971717\n",
      "Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task1 Loss: 0.6275, Task2 Loss: 0.2218, Task3 Loss: 0.0116, Total Loss: 0.8609\n",
      "Training Result\n",
      "No of epochs Trained:  8\n",
      "For Gender Task:\n",
      "For Class 0:\n",
      "Precision_0: 0.6171, Recall_0: 0.8928, Accuracy_0: 0.6210, F1 Score_0: 0.7298\n",
      "For Class 1:\n",
      "Precision_1: 0.6396, Recall_1: 0.2556, Accuracy_1: 0.6210, F1 Score_1: 0.3652\n",
      "For Glasses Task:\n",
      "For Class 0:\n",
      "Precision_0: 0.9344, Recall_0: 0.9982, Accuracy_0: 0.9333, F1 Score_0: 0.9653\n",
      "For Class 1:\n",
      "Precision_1: 0.7812, Recall_1: 0.0847, Accuracy_1: 0.9333, F1 Score_1: 0.1529\n",
      "For Pose Task:\n",
      "R2 Score: -0.6056\n",
      "Training error pose: 0.011344719128346586\n",
      "Validation Result\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of epochs Trained:  8\n",
      "For Gender Task:\n",
      "For Class 0:\n",
      "Precision_0: 0.6259, Recall_0: 0.8890, Accuracy_0: 0.6263, F1 Score_0: 0.7346\n",
      "For Class 1:\n",
      "Precision_1: 0.6283, Recall_1: 0.2609, Accuracy_1: 0.6263, F1 Score_1: 0.3687\n",
      "For Glasses Task:\n",
      "For Class 0:\n",
      "Precision_0: 0.9264, Recall_0: 0.9975, Accuracy_0: 0.9246, F1 Score_0: 0.9606\n",
      "For Class 1:\n",
      "Precision_1: 0.6364, Recall_1: 0.0519, Accuracy_1: 0.9246, F1 Score_1: 0.0959\n",
      "For Pose Task:\n",
      "R2 Score: -0.6243\n",
      "Training error pose: 0.011494811198541096\n",
      "Testing Result\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of epochs Trained:  8\n",
      "For Gender Task:\n",
      "For Class 0:\n",
      "Precision_0: 0.6675, Recall_0: 0.8208, Accuracy_0: 0.6365, F1 Score_0: 0.7363\n",
      "For Class 1:\n",
      "Precision_1: 0.5380, Recall_1: 0.3380, Accuracy_1: 0.6365, F1 Score_1: 0.4151\n",
      "For Glasses Task:\n",
      "For Class 0:\n",
      "Precision_0: 0.9284, Recall_0: 0.9985, Accuracy_0: 0.9276, F1 Score_0: 0.9622\n",
      "For Class 1:\n",
      "Precision_1: 0.8372, Recall_1: 0.0905, Accuracy_1: 0.9276, F1 Score_1: 0.1633\n",
      "For Pose Task:\n",
      "R2 Score: -1.2531\n",
      "Testing error pose: 0.013033263184422371\n",
      "Epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task1 Loss: 0.6090, Task2 Loss: 0.2105, Task3 Loss: 0.0117, Total Loss: 0.8312\n",
      "Training Result\n",
      "No of epochs Trained:  9\n",
      "For Gender Task:\n",
      "For Class 0:\n",
      "Precision_0: 0.6151, Recall_0: 0.9513, Accuracy_0: 0.6305, F1 Score_0: 0.7471\n",
      "For Class 1:\n",
      "Precision_1: 0.7519, Recall_1: 0.1987, Accuracy_1: 0.6305, F1 Score_1: 0.3143\n",
      "For Glasses Task:\n",
      "For Class 0:\n",
      "Precision_0: 0.9394, Recall_0: 0.9965, Accuracy_0: 0.9371, F1 Score_0: 0.9671\n",
      "For Class 1:\n",
      "Precision_1: 0.7840, Recall_1: 0.1653, Accuracy_1: 0.9371, F1 Score_1: 0.2730\n",
      "For Pose Task:\n",
      "R2 Score: -0.3377\n",
      "Training error pose: 0.009451387898929148\n",
      "Validation Result\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of epochs Trained:  9\n",
      "For Gender Task:\n",
      "For Class 0:\n",
      "Precision_0: 0.6221, Recall_0: 0.9474, Accuracy_0: 0.6346, F1 Score_0: 0.7510\n",
      "For Class 1:\n",
      "Precision_1: 0.7318, Recall_1: 0.1995, Accuracy_1: 0.6346, F1 Score_1: 0.3135\n",
      "For Glasses Task:\n",
      "For Class 0:\n",
      "Precision_0: 0.9340, Recall_0: 0.9954, Accuracy_0: 0.9309, F1 Score_0: 0.9637\n",
      "For Class 1:\n",
      "Precision_1: 0.7414, Recall_1: 0.1593, Accuracy_1: 0.9309, F1 Score_1: 0.2622\n",
      "For Pose Task:\n",
      "R2 Score: -0.3579\n",
      "Training error pose: 0.009609894693962165\n",
      "Testing Result\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of epochs Trained:  9\n",
      "For Gender Task:\n",
      "For Class 0:\n",
      "Precision_0: 0.6572, Recall_0: 0.8817, Accuracy_0: 0.6425, F1 Score_0: 0.7531\n",
      "For Class 1:\n",
      "Precision_1: 0.5713, Recall_1: 0.2553, Accuracy_1: 0.6425, F1 Score_1: 0.3529\n",
      "For Glasses Task:\n",
      "For Class 0:\n",
      "Precision_0: 0.9359, Recall_0: 0.9966, Accuracy_0: 0.9339, F1 Score_0: 0.9653\n",
      "For Class 1:\n",
      "Precision_1: 0.8280, Recall_1: 0.1935, Accuracy_1: 0.9339, F1 Score_1: 0.3136\n",
      "For Pose Task:\n",
      "R2 Score: -1.0682\n",
      "Testing error pose: 0.011963805548992812\n",
      "Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task1 Loss: 0.5955, Task2 Loss: 0.1955, Task3 Loss: 0.0109, Total Loss: 0.8019\n",
      "Training Result\n",
      "No of epochs Trained:  10\n",
      "For Gender Task:\n",
      "For Class 0:\n",
      "Precision_0: 0.6405, Recall_0: 0.7806, Accuracy_0: 0.6228, F1 Score_0: 0.7036\n",
      "For Class 1:\n",
      "Precision_1: 0.5815, Recall_1: 0.4104, Accuracy_1: 0.6228, F1 Score_1: 0.4812\n",
      "For Glasses Task:\n",
      "For Class 0:\n",
      "Precision_0: 0.9427, Recall_0: 0.9933, Accuracy_0: 0.9377, F1 Score_0: 0.9673\n",
      "For Class 1:\n",
      "Precision_1: 0.7079, Recall_1: 0.2132, Accuracy_1: 0.9377, F1 Score_1: 0.3277\n",
      "For Pose Task:\n",
      "R2 Score: -0.3452\n",
      "Training error pose: 0.009505931001874697\n",
      "Validation Result\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of epochs Trained:  10\n",
      "For Gender Task:\n",
      "For Class 0:\n",
      "Precision_0: 0.6459, Recall_0: 0.7633, Accuracy_0: 0.6189, F1 Score_0: 0.6997\n",
      "For Class 1:\n",
      "Precision_1: 0.5594, Recall_1: 0.4180, Accuracy_1: 0.6189, F1 Score_1: 0.4785\n",
      "For Glasses Task:\n",
      "For Class 0:\n",
      "Precision_0: 0.9364, Recall_0: 0.9929, Accuracy_0: 0.9311, F1 Score_0: 0.9638\n",
      "For Class 1:\n",
      "Precision_1: 0.6933, Recall_1: 0.1926, Accuracy_1: 0.9311, F1 Score_1: 0.3014\n",
      "For Pose Task:\n",
      "R2 Score: -0.3543\n",
      "Training error pose: 0.00958379354061825\n",
      "Testing Result\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of epochs Trained:  10\n",
      "For Gender Task:\n",
      "For Class 0:\n",
      "Precision_0: 0.6589, Recall_0: 0.7241, Accuracy_0: 0.5976, F1 Score_0: 0.6899\n",
      "For Class 1:\n",
      "Precision_1: 0.4679, Recall_1: 0.3929, Accuracy_1: 0.5976, F1 Score_1: 0.4271\n",
      "For Glasses Task:\n",
      "For Class 0:\n",
      "Precision_0: 0.9380, Recall_0: 0.9949, Accuracy_0: 0.9347, F1 Score_0: 0.9656\n",
      "For Class 1:\n",
      "Precision_1: 0.7876, Recall_1: 0.2236, Accuracy_1: 0.9347, F1 Score_1: 0.3483\n",
      "For Pose Task:\n",
      "R2 Score: -0.9422\n",
      "Testing error pose: 0.011235108927768819\n",
      "Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task1 Loss: 0.5563, Task2 Loss: 0.1738, Task3 Loss: 0.0107, Total Loss: 0.7408\n",
      "Training Result\n",
      "No of epochs Trained:  11\n",
      "For Gender Task:\n",
      "For Class 0:\n",
      "Precision_0: 0.7176, Recall_0: 0.8021, Accuracy_0: 0.7052, F1 Score_0: 0.7575\n",
      "For Class 1:\n",
      "Precision_1: 0.6829, Recall_1: 0.5745, Accuracy_1: 0.7052, F1 Score_1: 0.6241\n",
      "For Glasses Task:\n",
      "For Class 0:\n",
      "Precision_0: 0.9558, Recall_0: 0.9894, Accuracy_0: 0.9476, F1 Score_0: 0.9723\n",
      "For Class 1:\n",
      "Precision_1: 0.7429, Recall_1: 0.4017, Accuracy_1: 0.9476, F1 Score_1: 0.5215\n",
      "For Pose Task:\n",
      "R2 Score: -0.5645\n",
      "Training error pose: 0.01105726960238563\n",
      "Validation Result\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of epochs Trained:  11\n",
      "For Gender Task:\n",
      "For Class 0:\n",
      "Precision_0: 0.7032, Recall_0: 0.7633, Accuracy_0: 0.6749, F1 Score_0: 0.7320\n",
      "For Class 1:\n",
      "Precision_1: 0.6264, Recall_1: 0.5519, Accuracy_1: 0.6749, F1 Score_1: 0.5868\n",
      "For Glasses Task:\n",
      "For Class 0:\n",
      "Precision_0: 0.9454, Recall_0: 0.9854, Accuracy_0: 0.9340, F1 Score_0: 0.9650\n",
      "For Class 1:\n",
      "Precision_1: 0.6466, Recall_1: 0.3185, Accuracy_1: 0.9340, F1 Score_1: 0.4268\n",
      "For Pose Task:\n",
      "R2 Score: -0.6175\n",
      "Training error pose: 0.011446420662105083\n",
      "Testing Result\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of epochs Trained:  11\n",
      "For Gender Task:\n",
      "For Class 0:\n",
      "Precision_0: 0.7404, Recall_0: 0.6422, Accuracy_0: 0.6396, F1 Score_0: 0.6878\n",
      "For Class 1:\n",
      "Precision_1: 0.5230, Recall_1: 0.6353, Accuracy_1: 0.6396, F1 Score_1: 0.5737\n",
      "For Glasses Task:\n",
      "For Class 0:\n",
      "Precision_0: 0.9457, Recall_0: 0.9894, Accuracy_0: 0.9378, F1 Score_0: 0.9671\n",
      "For Class 1:\n",
      "Precision_1: 0.7238, Recall_1: 0.3291, Accuracy_1: 0.9378, F1 Score_1: 0.4525\n",
      "For Pose Task:\n",
      "R2 Score: -1.6700\n",
      "Testing error pose: 0.01544495880165521\n",
      "Epoch: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task1 Loss: 0.5045, Task2 Loss: 0.1654, Task3 Loss: 0.0104, Total Loss: 0.6803\n",
      "Training Result\n",
      "No of epochs Trained:  12\n",
      "For Gender Task:\n",
      "For Class 0:\n",
      "Precision_0: 0.6731, Recall_0: 0.8811, Accuracy_0: 0.6864, F1 Score_0: 0.7632\n",
      "For Class 1:\n",
      "Precision_1: 0.7264, Recall_1: 0.4246, Accuracy_1: 0.6864, F1 Score_1: 0.5359\n",
      "For Glasses Task:\n",
      "For Class 0:\n",
      "Precision_0: 0.9447, Recall_0: 0.9968, Accuracy_0: 0.9428, F1 Score_0: 0.9700\n",
      "For Class 1:\n",
      "Precision_1: 0.8494, Recall_1: 0.2386, Accuracy_1: 0.9428, F1 Score_1: 0.3725\n",
      "For Pose Task:\n",
      "R2 Score: -0.5154\n",
      "Training error pose: 0.01071685288909329\n",
      "Validation Result\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of epochs Trained:  12\n",
      "For Gender Task:\n",
      "For Class 0:\n",
      "Precision_0: 0.6649, Recall_0: 0.8536, Accuracy_0: 0.6646, F1 Score_0: 0.7475\n",
      "For Class 1:\n",
      "Precision_1: 0.6637, Recall_1: 0.4016, Accuracy_1: 0.6646, F1 Score_1: 0.5004\n",
      "For Glasses Task:\n",
      "For Class 0:\n",
      "Precision_0: 0.9343, Recall_0: 0.9947, Accuracy_0: 0.9306, F1 Score_0: 0.9636\n",
      "For Class 1:\n",
      "Precision_1: 0.7213, Recall_1: 0.1630, Accuracy_1: 0.9306, F1 Score_1: 0.2659\n",
      "For Pose Task:\n",
      "R2 Score: -0.5584\n",
      "Training error pose: 0.011028663760849407\n",
      "Testing Result\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of epochs Trained:  12\n",
      "For Gender Task:\n",
      "For Class 0:\n",
      "Precision_0: 0.6681, Recall_0: 0.8005, Accuracy_0: 0.6308, F1 Score_0: 0.7283\n",
      "For Class 1:\n",
      "Precision_1: 0.5242, Recall_1: 0.3559, Accuracy_1: 0.6308, F1 Score_1: 0.4240\n",
      "For Glasses Task:\n",
      "For Class 0:\n",
      "Precision_0: 0.9341, Recall_0: 0.9979, Accuracy_0: 0.9331, F1 Score_0: 0.9649\n",
      "For Class 1:\n",
      "Precision_1: 0.8701, Recall_1: 0.1683, Accuracy_1: 0.9331, F1 Score_1: 0.2821\n",
      "For Pose Task:\n",
      "R2 Score: -1.6359\n",
      "Testing error pose: 0.015247434176796791\n",
      "Epoch: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task1 Loss: 0.4259, Task2 Loss: 0.1416, Task3 Loss: 0.0100, Total Loss: 0.5775\n",
      "Training Result\n",
      "No of epochs Trained:  13\n",
      "For Gender Task:\n",
      "For Class 0:\n",
      "Precision_0: 0.6126, Recall_0: 0.9735, Accuracy_0: 0.6319, F1 Score_0: 0.7520\n",
      "For Class 1:\n",
      "Precision_1: 0.8295, Recall_1: 0.1731, Accuracy_1: 0.6319, F1 Score_1: 0.2864\n",
      "For Glasses Task:\n",
      "For Class 0:\n",
      "Precision_0: 0.9410, Recall_0: 0.9968, Accuracy_0: 0.9389, F1 Score_0: 0.9681\n",
      "For Class 1:\n",
      "Precision_1: 0.8148, Recall_1: 0.1858, Accuracy_1: 0.9389, F1 Score_1: 0.3026\n",
      "For Pose Task:\n",
      "R2 Score: -3.3015\n",
      "Training error pose: 0.030381522825862987\n",
      "Validation Result\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of epochs Trained:  13\n",
      "For Gender Task:\n",
      "For Class 0:\n",
      "Precision_0: 0.6140, Recall_0: 0.9681, Accuracy_0: 0.6274, F1 Score_0: 0.7514\n",
      "For Class 1:\n",
      "Precision_1: 0.7759, Recall_1: 0.1537, Accuracy_1: 0.6274, F1 Score_1: 0.2566\n",
      "For Glasses Task:\n",
      "For Class 0:\n",
      "Precision_0: 0.9308, Recall_0: 0.9960, Accuracy_0: 0.9280, F1 Score_0: 0.9623\n",
      "For Class 1:\n",
      "Precision_1: 0.7045, Recall_1: 0.1148, Accuracy_1: 0.9280, F1 Score_1: 0.1975\n",
      "For Pose Task:\n",
      "R2 Score: -3.2110\n",
      "Training error pose: 0.029800592522536005\n",
      "Testing Result\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of epochs Trained:  13\n",
      "For Gender Task:\n",
      "For Class 0:\n",
      "Precision_0: 0.6533, Recall_0: 0.9340, Accuracy_0: 0.6527, F1 Score_0: 0.7688\n",
      "For Class 1:\n",
      "Precision_1: 0.6486, Recall_1: 0.1972, Accuracy_1: 0.6527, F1 Score_1: 0.3025\n",
      "For Glasses Task:\n",
      "For Class 0:\n",
      "Precision_0: 0.9333, Recall_0: 0.9977, Accuracy_0: 0.9322, F1 Score_0: 0.9644\n",
      "For Class 1:\n",
      "Precision_1: 0.8514, Recall_1: 0.1583, Accuracy_1: 0.9322, F1 Score_1: 0.2669\n",
      "For Pose Task:\n",
      "R2 Score: -3.6999\n",
      "Testing error pose: 0.02718732504210636\n",
      "Epoch: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task1 Loss: 0.3655, Task2 Loss: 0.1304, Task3 Loss: 0.0097, Total Loss: 0.5057\n",
      "Training Result\n",
      "No of epochs Trained:  14\n",
      "For Gender Task:\n",
      "For Class 0:\n",
      "Precision_0: 0.8708, Recall_0: 0.4529, Accuracy_0: 0.6477, F1 Score_0: 0.5959\n",
      "For Class 1:\n",
      "Precision_1: 0.5529, Recall_1: 0.9096, Accuracy_1: 0.6477, F1 Score_1: 0.6877\n",
      "For Glasses Task:\n",
      "For Class 0:\n",
      "Precision_0: 0.9552, Recall_0: 0.9754, Accuracy_0: 0.9346, F1 Score_0: 0.9652\n",
      "For Class 1:\n",
      "Precision_1: 0.5529, Recall_1: 0.3997, Accuracy_1: 0.9346, F1 Score_1: 0.4640\n",
      "For Pose Task:\n",
      "R2 Score: -0.8086\n",
      "Training error pose: 0.012783537820789469\n",
      "Validation Result\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of epochs Trained:  14\n",
      "For Gender Task:\n",
      "For Class 0:\n",
      "Precision_0: 0.8077, Recall_0: 0.3713, Accuracy_0: 0.5829, F1 Score_0: 0.5087\n",
      "For Class 1:\n",
      "Precision_1: 0.5008, Recall_1: 0.8770, Accuracy_1: 0.5829, F1 Score_1: 0.6375\n",
      "For Glasses Task:\n",
      "For Class 0:\n",
      "Precision_0: 0.9432, Recall_0: 0.9613, Accuracy_0: 0.9109, F1 Score_0: 0.9522\n",
      "For Class 1:\n",
      "Precision_1: 0.3990, Recall_1: 0.3074, Accuracy_1: 0.9109, F1 Score_1: 0.3473\n",
      "For Pose Task:\n",
      "R2 Score: -0.8602\n",
      "Training error pose: 0.013164260956857885\n",
      "Testing Result\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of epochs Trained:  14\n",
      "For Gender Task:\n",
      "For Class 0:\n",
      "Precision_0: 0.7770, Recall_0: 0.2896, Accuracy_0: 0.5094, F1 Score_0: 0.4219\n",
      "For Class 1:\n",
      "Precision_1: 0.4293, Recall_1: 0.8654, Accuracy_1: 0.5094, F1 Score_1: 0.5739\n",
      "For Glasses Task:\n",
      "For Class 0:\n",
      "Precision_0: 0.9435, Recall_0: 0.9662, Accuracy_0: 0.9155, F1 Score_0: 0.9547\n",
      "For Class 1:\n",
      "Precision_1: 0.4421, Recall_1: 0.3166, Accuracy_1: 0.9155, F1 Score_1: 0.3690\n",
      "For Pose Task:\n",
      "R2 Score: -1.8905\n",
      "Testing error pose: 0.01672070243341081\n",
      "Epoch: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task1 Loss: 0.3100, Task2 Loss: 0.1162, Task3 Loss: 0.0094, Total Loss: 0.4356\n",
      "Training Result\n",
      "No of epochs Trained:  15\n",
      "For Gender Task:\n",
      "For Class 0:\n",
      "Precision_0: 0.6750, Recall_0: 0.9609, Accuracy_0: 0.7122, F1 Score_0: 0.7930\n",
      "For Class 1:\n",
      "Precision_1: 0.8777, Recall_1: 0.3773, Accuracy_1: 0.7122, F1 Score_1: 0.5278\n",
      "For Glasses Task:\n",
      "For Class 0:\n",
      "Precision_0: 0.9476, Recall_0: 0.9968, Accuracy_0: 0.9458, F1 Score_0: 0.9716\n",
      "For Class 1:\n",
      "Precision_1: 0.8691, Recall_1: 0.2809, Accuracy_1: 0.9458, F1 Score_1: 0.4246\n",
      "For Pose Task:\n",
      "R2 Score: -1.0761\n",
      "Training error pose: 0.01465693746794419\n",
      "Validation Result\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of epochs Trained:  15\n",
      "For Gender Task:\n",
      "For Class 0:\n",
      "Precision_0: 0.6583, Recall_0: 0.9445, Accuracy_0: 0.6826, F1 Score_0: 0.7759\n",
      "For Class 1:\n",
      "Precision_1: 0.8048, Recall_1: 0.3183, Accuracy_1: 0.6826, F1 Score_1: 0.4562\n",
      "For Glasses Task:\n",
      "For Class 0:\n",
      "Precision_0: 0.9364, Recall_0: 0.9932, Accuracy_0: 0.9314, F1 Score_0: 0.9639\n",
      "For Class 1:\n",
      "Precision_1: 0.7027, Recall_1: 0.1926, Accuracy_1: 0.9314, F1 Score_1: 0.3023\n",
      "For Pose Task:\n",
      "R2 Score: -1.0412\n",
      "Training error pose: 0.01444483127977167\n",
      "Testing Result\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of epochs Trained:  15\n",
      "For Gender Task:\n",
      "For Class 0:\n",
      "Precision_0: 0.6788, Recall_0: 0.9017, Accuracy_0: 0.6755, F1 Score_0: 0.7746\n",
      "For Class 1:\n",
      "Precision_1: 0.6601, Recall_1: 0.3092, Accuracy_1: 0.6755, F1 Score_1: 0.4211\n",
      "For Glasses Task:\n",
      "For Class 0:\n",
      "Precision_0: 0.9383, Recall_0: 0.9955, Accuracy_0: 0.9355, F1 Score_0: 0.9661\n",
      "For Class 1:\n",
      "Precision_1: 0.8108, Recall_1: 0.2261, Accuracy_1: 0.9355, F1 Score_1: 0.3536\n",
      "For Pose Task:\n",
      "R2 Score: -2.1000\n",
      "Testing error pose: 0.017932062073811598\n",
      "Epoch: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task1 Loss: 0.2279, Task2 Loss: 0.0991, Task3 Loss: 0.0093, Total Loss: 0.3363\n",
      "Early stopping triggered.\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(NumEpochs):\n",
    "    print(\"Epoch: %d\" % epoch)\n",
    "    rloss1 = 0.0\n",
    "    rloss2 = 0.0\n",
    "    rloss3 = 0.0\n",
    "    rnet_loss = 0.0\n",
    "\n",
    "    multi_task_net.train()\n",
    "    for i, data in enumerate(train_dataloader, 0):\n",
    "        img, label_gender, label_glass, label_pose, imageName, TaskwiseLabelPresence = data\n",
    "        img = img.to(device)\n",
    "        label_gender = label_gender.to(device)\n",
    "        label_glass = label_glass.to(device)\n",
    "        label_pose = label_pose.to(device)\n",
    "        TaskwiseLabelPresence = TaskwiseLabelPresence.numpy()\n",
    "      \n",
    "        img, label_gender, label_glass, label_pose = img.float(), label_gender.float(), label_glass.float(), label_pose.float()\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        FC_output_gender, FC_output_glasses, FC_output_angle = multi_task_net(img)\n",
    "\n",
    "        gender_IndSelect = np.where(TaskwiseLabelPresence[:, 0] == 1)\n",
    "        glasses_IndSelect = np.where(TaskwiseLabelPresence[:, 1] == 1)\n",
    "        pose_IndSelect = np.where(TaskwiseLabelPresence[:, 2] == 1)\n",
    "\n",
    "        if gender_IndSelect[0].shape[0] != 0:\n",
    "            loss1 = criterion_task1(FC_output_gender[gender_IndSelect[0]], label_gender[gender_IndSelect[0]])\n",
    "            rloss1 += loss1.item()\n",
    "        else:\n",
    "            loss1 = 0.0\n",
    "\n",
    "        if glasses_IndSelect[0].shape[0] != 0:\n",
    "            loss2 = criterion_task2(FC_output_glasses[glasses_IndSelect], label_glass[glasses_IndSelect])\n",
    "            rloss2 += loss2.item()\n",
    "        else:\n",
    "            loss2 = 0.0\n",
    "\n",
    "        if pose_IndSelect[0].shape[0] != 0:\n",
    "            loss3 = criterion_task3(FC_output_angle[pose_IndSelect[0]], label_pose[pose_IndSelect[0]])\n",
    "            rloss3 += loss3.item()\n",
    "        else:\n",
    "            loss3 = 0.0\n",
    "\n",
    "        NetLoss = loss1 + loss2 + loss3\n",
    "\n",
    "        if epoch != 0:\n",
    "            NetLoss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        rnet_loss += NetLoss.item()\n",
    "\n",
    "    print(\"Task1 Loss: {:.4f}, Task2 Loss: {:.4f}, Task3 Loss: {:.4f}, Total Loss: {:.4f}\".format(\n",
    "        rloss1 / len(train_dataloader),\n",
    "        rloss2 / len(train_dataloader),\n",
    "        rloss3 / len(train_dataloader),\n",
    "        rnet_loss / len(train_dataloader)\n",
    "    ))\n",
    "\n",
    "\n",
    "    multi_task_net.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0.0\n",
    "        for i, data in enumerate(val_dataloader, 0):\n",
    "            img, label_gender, label_glass, label_pose, imageName, TaskwiseLabelPresence = data\n",
    "            img = img.to(device)\n",
    "            label_gender = label_gender.to(device)\n",
    "            label_glass = label_glass.to(device)\n",
    "            label_pose = label_pose.to(device)\n",
    "            TaskwiseLabelPresence = TaskwiseLabelPresence.numpy()\n",
    "            img, label_gender, label_glass, label_pose = img.float(), label_gender.float(), label_glass.float(), label_pose.float()\n",
    "\n",
    "            FC_output_gender, FC_output_glasses, FC_output_angle = multi_task_net(img)\n",
    "\n",
    "            gender_IndSelect = np.where(TaskwiseLabelPresence[:, 0] == 1)\n",
    "            glasses_IndSelect = np.where(TaskwiseLabelPresence[:, 1] == 1)\n",
    "            pose_IndSelect = np.where(TaskwiseLabelPresence[:, 2] == 1)\n",
    "\n",
    "            loss1 = criterion_task1(FC_output_gender[gender_IndSelect[0]], label_gender[gender_IndSelect[0]]) if gender_IndSelect[0].shape[0] != 0 else 0.0\n",
    "            loss2 = criterion_task2(FC_output_glasses[glasses_IndSelect], label_glass[glasses_IndSelect]) if glasses_IndSelect[0].shape[0] != 0 else 0.0\n",
    "            loss3 = criterion_task3(FC_output_angle[pose_IndSelect[0]], label_pose[pose_IndSelect[0]]) if pose_IndSelect[0].shape[0] != 0 else 0.0\n",
    "\n",
    "\n",
    "            val_loss += (loss1 + loss2 + loss3).item()\n",
    "\n",
    "\n",
    "    val_loss /= len(val_dataloader)\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model_state = multi_task_net.state_dict()\n",
    "        patience = 0\n",
    "    else:\n",
    "        patience += 1\n",
    "        if patience >= early_stopping_rounds:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "\n",
    "    print('Training Result')\n",
    "    training_result(epoch,multi_task_net, train_dataloader)\n",
    "    print('Validation Result')\n",
    "    validation_result(epoch,multi_task_net, val_dataloader)\n",
    "    print('Testing Result')\n",
    "    testing_result(epoch,multi_task_net, test_dataloader)\n",
    "\n",
    "\n",
    "    multi_task_net.load_state_dict(best_model_state)\n",
    "    torch.save(multi_task_net, 'Teacher_MTL.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2c06e2",
   "metadata": {
    "papermill": {
     "duration": 0.023714,
     "end_time": "2024-04-19T11:57:49.839968",
     "exception": false,
     "start_time": "2024-04-19T11:57:49.816254",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7060946c",
   "metadata": {
    "papermill": {
     "duration": 0.023443,
     "end_time": "2024-04-19T11:57:49.887290",
     "exception": false,
     "start_time": "2024-04-19T11:57:49.863847",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7d9b9f",
   "metadata": {
    "papermill": {
     "duration": 0.022391,
     "end_time": "2024-04-19T11:57:49.932826",
     "exception": false,
     "start_time": "2024-04-19T11:57:49.910435",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc2c87c",
   "metadata": {
    "papermill": {
     "duration": 0.023917,
     "end_time": "2024-04-19T11:57:49.980344",
     "exception": false,
     "start_time": "2024-04-19T11:57:49.956427",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248c23ac",
   "metadata": {
    "papermill": {
     "duration": 0.023456,
     "end_time": "2024-04-19T11:57:50.027119",
     "exception": false,
     "start_time": "2024-04-19T11:57:50.003663",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968c83bc",
   "metadata": {
    "papermill": {
     "duration": 0.024254,
     "end_time": "2024-04-19T11:57:50.074871",
     "exception": false,
     "start_time": "2024-04-19T11:57:50.050617",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16f63ae",
   "metadata": {
    "papermill": {
     "duration": 0.0238,
     "end_time": "2024-04-19T11:57:50.122426",
     "exception": false,
     "start_time": "2024-04-19T11:57:50.098626",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ee8bbc",
   "metadata": {
    "papermill": {
     "duration": 0.022084,
     "end_time": "2024-04-19T11:57:50.167670",
     "exception": false,
     "start_time": "2024-04-19T11:57:50.145586",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ae84b9",
   "metadata": {
    "papermill": {
     "duration": 0.022234,
     "end_time": "2024-04-19T11:57:50.212099",
     "exception": false,
     "start_time": "2024-04-19T11:57:50.189865",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cc96b9",
   "metadata": {
    "papermill": {
     "duration": 0.022878,
     "end_time": "2024-04-19T11:57:50.258458",
     "exception": false,
     "start_time": "2024-04-19T11:57:50.235580",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 4736610,
     "sourceId": 8035171,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30674,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 8029.841858,
   "end_time": "2024-04-19T11:57:53.346836",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-19T09:44:03.504978",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
